# AI Coding Guidelines for Cartellino Parser

## Project Overview
This Python project parses Italian payroll time sheets ("cartellini") from PDFs generated by Azienda Ospedaliera di Perugia / INSIEL systems. It consists of two main packages:
- `cartellino_parser`: Core PDF parsing logic extracting days, time pairs, and totals
- `drive_scanner`: Google Drive integration for bulk scanning and filtering cartellini

## Architecture Patterns
- **Data Flow**: PDF text extraction -> structured parsing -> validation -> CSV/JSON outputs
- **Core API**: Use `from cartellino_parser.parser import parse_pdf` for programmatic access
- **Data Structures**:
  - `ParsedCartellino` dataclass with `meta`, `days_df`, `pairs_df`, `totals`, `validation`
  - Frozen dataclasses for immutable records (`DayRecord`, `PairRecord`)
- **Output Formats**:
  - `*.days.csv`: Daily work hours (columns: year, month, day, dow, mo_f, mo_t, mo_lav, raw)
  - `*.pairs.csv`: Time entry/exit pairs (columns: year, month, day, dow, pair_index, entry_ts, exit_ts, duration_hhmm, turno, entry_raw, exit_raw)
  - `*.totals.json`: Aggregated totals (ore_lavorate, ore_dovute_programmate, etc.)
  - `*.report.json`: Complete metadata, totals, and validation results

## Development Workflow
- **Setup**: `python -m pip install -e .[dev]` (installs pdfplumber, pandas, pytest)
- **CLI Parsing**: `python -m cartellino_parser.cli parse --input documents --out output`
- **Testing**: `pytest`
- **Drive Scan**: `python -m drive_scanner.scan_directory --root <FOLDER_ID> --out output -v`
- **Drive Filter**: `python -m drive_scanner.filter_scan --manifest manifest.json --out output --report report.json -v`
- **PowerShell Tasks**: `./tasks.ps1 scan ...`, `./tasks.ps1 filter ...`, `./tasks.ps1 test`

## Code Conventions
- **Imports**: Relative imports within packages, absolute for external deps
- **Error Handling**: Raise `CartellinoParseError` for parsing failures
- **Logging**: Use `logging.getLogger(__name__)` with INFO level for CLI output
- **DataFrames**: Always include specific column ordering when creating DataFrames
- **Validation**: Compare parsed sums against totals (e.g., `days_df["mo_lav"].sum()` vs `totals["ore_lavorate"]`)
- **File Paths**: Use `pathlib.Path` in parser modules; Drive modules use `os.path` for output paths

## Key Files to Reference
- `src/cartellino_parser/parser.py`: Main `parse_pdf()` function orchestrating extraction and parsing
- `src/cartellino_parser/models.py`: Data structures and error classes
- `src/cartellino_parser/parse_days.py`: Day-level parsing logic
- `src/drive_scanner/config.py`: Google Drive API configuration and filtering rules
- `src/drive_scanner/scan_directory.py`: Builds Drive manifests
- `src/drive_scanner/filter_scan.py`: Filters/validates PDFs and writes parsed outputs
- `tests/test_filter_scan_merge.py`: Merge behavior for filtered manifests

## Integration Points
- **Google Drive API**: Requires `GOOGLE_CLIENT_ID`, `GOOGLE_CLIENT_SECRET`, `DRIVE_ROOT_FOLDER_ID` env vars
- **PDF Processing**: Uses pdfplumber for text extraction, handles multi-page documents
- **Time Parsing**: Italian locale datetime parsing for entry/exit timestamps
- **Filtering**: Excludes payroll documents (cedolino, busta paga) from cartellini scans
- **ZIP Handling**: Drive scan includes ZIP files in manifests; filtering can decide how to handle them

## Common Patterns
- **Text Preprocessing**: Split PDF text into lines, parse metadata first (employee, month/year)
- **Iterative Parsing**: Parse days, then pairs, then totals with shared metadata context
- **Validation Logic**: Cross-check parsed data against embedded totals for consistency
- **Output Layout**: `output/<employee>/<file_tag>/days.csv`, `pairs.csv`, `totals.json`, `report.json`
- **Manifest Schema**: `root_id`, `generated_at`, `employee_count`, `employees[]` with `included`, `skipped`, `excluded_folders`, `counts`
